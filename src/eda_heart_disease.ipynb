{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9aecaf",
   "metadata": {},
   "source": [
    "# Factores asociados a enfermedades cardiovasculares\n",
    "**Autor:** JLBM  \n",
    "**Fecha:** 17/09/2025  \n",
    "**Notebook:** eda_heart_disease.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "## Propósito\n",
    "Este cuaderno guía un **Análisis Exploratorio de Datos (EDA)** de un archivo `.csv` con miras a preparar un **modelo predictivo de *Machine Learning*** sobre enfermedades cardiovasculares.\n",
    "\n",
    "> **Instrucciones rápidas**\n",
    "> 1. Actualiza la variable `CSV_PATH` en la siguiente celda con la ruta a tu archivo `.csv`.\n",
    "> 2. Ejecuta todas las celdas en orden.\n",
    "> 3. Al finalizar, se generará automáticamente un reporte en Word: **“report_eda_heart_disease v1.docx”** con los principales hallazgos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Configuración inicial ============\n",
    "# Ajusta esta ruta a tu archivo CSV antes de ejecutar\n",
    "CSV_PATH = Path(__file__).parent  # carpeta donde está el script\n",
    "\n",
    "# Opciones generales\n",
    "SAVE_DIR = \"outputs\"\n",
    "RANDOM_STATE = 42\n",
    "REPORT_FILENAME = \"report_eda_heart_disease.docx\"\n",
    "\n",
    "import os, sys, json, math, textwrap, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualización (evitar seaborn por compatibilidad)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelos y utilidades\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, r2_score\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Reporte en Word\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def savefig(name):\n",
    "    path = os.path.join(SAVE_DIR, f\"{name}.png\")\n",
    "    plt.savefig(path, bbox_inches=\"tight\", dpi=140)\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "def detect_types(df, cat_threshold=20):\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Categóricas: dtypes 'object'/'category' o numéricas con pocas categorías\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    for c in num_cols:\n",
    "        if df[c].nunique(dropna=True) <= cat_threshold:\n",
    "            if c not in cat_cols:\n",
    "                cat_cols.append(c)\n",
    "    # Evitar duplicados y asegurar separación\n",
    "    cat_cols = list(dict.fromkeys(cat_cols))\n",
    "    num_cols = [c for c in num_cols if c not in cat_cols]\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "def summarize_missing(df):\n",
    "    miss = df.isna().mean().sort_values(ascending=False)\n",
    "    return miss[miss > 0]\n",
    "\n",
    "def iqr_outliers(series):\n",
    "    q1, q3 = np.nanpercentile(series, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    mask = (series < lo) | (series > hi)\n",
    "    return int(mask.sum()), float(lo), float(hi)\n",
    "\n",
    "def auto_target(df):\n",
    "    # Heurística: buscar columnas típicas de etiqueta\n",
    "    candidates = [\"target\", \"disease\", \"heart_disease\", \"outcome\", \"label\", \"y\"]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in candidates or \"disease\" in c.lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def is_classification(y):\n",
    "    return pd.api.types.is_integer_dtype(y) or y.nunique()<=20\n",
    "\n",
    "def corr_df(df, cols):\n",
    "    return df[cols].corr(method=\"pearson\")\n",
    "\n",
    "def plot_hist(series, title):\n",
    "    plt.figure()\n",
    "    plt.hist(series.dropna(), bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(series.name)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    return savefig(f\"hist_{series.name}\")\n",
    "\n",
    "def plot_bar_counts(series, title):\n",
    "    plt.figure()\n",
    "    counts = series.astype(str).value_counts(dropna=False)\n",
    "    counts.plot(kind=\"bar\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(series.name)\n",
    "    plt.ylabel(\"Cuenta\")\n",
    "    return savefig(f\"bar_{series.name}\")\n",
    "\n",
    "def plot_scatter(x, y, title):\n",
    "    plt.figure()\n",
    "    plt.scatter(x, y, alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x.name); plt.ylabel(y.name)\n",
    "    return savefig(f\"scatter_{x.name}_vs_{y.name}\")\n",
    "\n",
    "def plot_box(y, x_cat, title):\n",
    "    # Dibujar boxplots por categoría\n",
    "    plt.figure()\n",
    "    cats = x_cat.astype(str).unique()\n",
    "    data = [y[x_cat.astype(str)==c].dropna() for c in cats]\n",
    "    plt.boxplot(data, labels=cats, showfliers=False)\n",
    "    plt.title(title); plt.xlabel(x_cat.name); plt.ylabel(y.name)\n",
    "    return savefig(f\"box_{y.name}_by_{x_cat.name}\")\n",
    "\n",
    "def plot_heatmap(mat, labels, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(mat, interpolation=\"nearest\")\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    return savefig(\"heatmap_correlaciones\")\n",
    "\n",
    "def pca_plot(X_num_scaled, title, y=None):\n",
    "    pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "    comps = pca.fit_transform(X_num_scaled)\n",
    "    plt.figure()\n",
    "    plt.scatter(comps[:,0], comps[:,1], alpha=0.6)\n",
    "    plt.title(f\"{title} (VarExp: {pca.explained_variance_ratio_.sum():.2f})\")\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "    return savefig(\"pca_2d\"), pca.explained_variance_ratio_\n",
    "\n",
    "def build_report(context):\n",
    "    doc = Document()\n",
    "    # Portada simple\n",
    "    h = doc.add_heading(case_name, level=1)\n",
    "    h.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    p = doc.add_paragraph(f\"Autor: {context['author']} | Fecha: {context['date']}\")\n",
    "    p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_paragraph(\"Reporte: report_eda_heart_disease v1\")\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # Objetivos\n",
    "    doc.add_heading(\"Objetivos del reporte\", level=2)\n",
    "    doc.add_paragraph(\"• Presentar un resumen claro y accionable del análisis exploratorio con miras a un modelo predictivo.\")\n",
    "\n",
    "    # Descripción del dataset\n",
    "    doc.add_heading(\"Descripción del conjunto de datos y sus variables\", level=2)\n",
    "    doc.add_paragraph(f\"Registros: {context['n_rows']:,} | Variables: {context['n_cols']}\")\n",
    "    doc.add_paragraph(f\"Variable objetivo (si aplica): {context.get('target','N/D')}\")\n",
    "    if context['missing_top']:\n",
    "        doc.add_paragraph(\"Principales variables con valores faltantes:\")\n",
    "        for name, frac in context['missing_top']:\n",
    "            doc.add_paragraph(f\"• {name}: {frac:.1%}\")\n",
    "    else:\n",
    "        doc.add_paragraph(\"No se identificaron valores faltantes relevantes.\")\n",
    "\n",
    "    # Univariado\n",
    "    doc.add_heading(\"Principales hallazgos - Análisis univariado\", level=2)\n",
    "    for line in context['univariate_findings'][:6]:\n",
    "        doc.add_paragraph(f\"• {line}\")\n",
    "    if context['example_plots'].get('univariate'):\n",
    "        doc.add_paragraph(\"Ilustraciones:\")\n",
    "        for fig in context['example_plots']['univariate'][:3]:\n",
    "            doc.add_picture(fig, width=Inches(5.5))\n",
    "\n",
    "    # Bivariado\n",
    "    doc.add_heading(\"Principales hallazgos - Análisis bivariado\", level=2)\n",
    "    for line in context['bivariate_findings'][:6]:\n",
    "        doc.add_paragraph(f\"• {line}\")\n",
    "    if context['example_plots'].get('bivariate'):\n",
    "        doc.add_paragraph(\"Ilustraciones:\")\n",
    "        for fig in context['example_plots']['bivariate'][:3]:\n",
    "            doc.add_picture(fig, width=Inches(5.5))\n",
    "\n",
    "    # Multivariado\n",
    "    doc.add_heading(\"Principales hallazgos - Análisis multivariado\", level=2)\n",
    "    for line in context['multivariate_findings'][:6]:\n",
    "        doc.add_paragraph(f\"• {line}\")\n",
    "    if context['example_plots'].get('multivariate'):\n",
    "        doc.add_paragraph(\"Ilustraciones:\")\n",
    "        for fig in context['example_plots']['multivariate'][:3]:\n",
    "            doc.add_picture(fig, width=Inches(5.5))\n",
    "\n",
    "    # Conclusiones\n",
    "    doc.add_heading(\"Conclusiones\", level=2)\n",
    "    for line in context['conclusions'][:6]:\n",
    "        doc.add_paragraph(f\"• {line}\")\n",
    "\n",
    "    # Guardar\n",
    "    report_path = REPORT_FILENAME\n",
    "    doc.save(report_path)\n",
    "    return report_path\n",
    "\n",
    "print(\"✅ Librerías importadas y utilidades definidas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Carga de datos ============\n",
    "assert CSV_PATH != Path(__file__).parent  # carpeta donde está el script\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "original_shape = df.shape\n",
    "print(\"Dimensiones:\", original_shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Perfil general y limpieza ligera ============\n",
    "df_ = df.copy()\n",
    "\n",
    "# Tipos y detección\n",
    "num_cols, cat_cols = detect_types(df_)\n",
    "print(\"Numéricas:\", len(num_cols), \"| Categóricas:\", len(cat_cols))\n",
    "\n",
    "# Duplicados\n",
    "dups = df_.duplicated().sum()\n",
    "print(\"Duplicados:\", dups)\n",
    "if dups > 0:\n",
    "    df_ = df_.drop_duplicates()\n",
    "\n",
    "# Faltantes\n",
    "missing = summarize_missing(df_)\n",
    "display(missing.to_frame(\"proporción\"))\n",
    "\n",
    "# Estadísticos básicos\n",
    "display(df_[num_cols].describe().T)\n",
    "\n",
    "# Guardar lista de columnas\n",
    "with open(os.path.join(SAVE_DIR, \"columns.json\"), \"w\") as f:\n",
    "    json.dump({\"numeric\": num_cols, \"categorical\": cat_cols}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Análisis univariado ============\n",
    "example_plots_uni = []\n",
    "\n",
    "# Numéricas\n",
    "for c in num_cols[:12]:  # limitar para notebooks ligeros\n",
    "    path = plot_hist(df_[c], f\"Histograma: {c}\")\n",
    "    example_plots_uni.append(path)\n",
    "\n",
    "# Categóricas\n",
    "for c in cat_cols[:12]:\n",
    "    path = plot_bar_counts(df_[c], f\"Conteos: {c}\")\n",
    "    example_plots_uni.append(path)\n",
    "\n",
    "# Outliers (IQR)\n",
    "uni_findings = []\n",
    "for c in num_cols:\n",
    "    n_out, lo, hi = iqr_outliers(df_[c].dropna())\n",
    "    if n_out>0:\n",
    "        uni_findings.append(f\"{c}: {n_out} potenciales outliers (IQR), límites [{lo:.2f}, {hi:.2f}]\")\n",
    "    else:\n",
    "        uni_findings.append(f\"{c}: sin outliers relevantes por IQR\")\n",
    "\n",
    "print(\"Ejemplos de gráficas univariadas guardadas en\", SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8afb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Análisis bivariado ============\n",
    "example_plots_bi = []\n",
    "\n",
    "# Correlaciones numéricas\n",
    "if len(num_cols) >= 2:\n",
    "    corr = corr_df(df_, num_cols)\n",
    "    fig_path = plot_heatmap(corr.values, num_cols, \"Matriz de correlaciones (Pearson)\")\n",
    "    example_plots_bi.append(fig_path)\n",
    "    # Top correlaciones absolutas\n",
    "    corr_vals = corr.abs().where(~np.eye(corr.shape[0], dtype=bool)).stack().sort_values(ascending=False)\n",
    "    top_corr = corr_vals.head(5)\n",
    "else:\n",
    "    top_corr = pd.Series(dtype=float)\n",
    "\n",
    "# Boxplots: cat vs num\n",
    "for cn in cat_cols[:5]:\n",
    "    for nn in num_cols[:3]:\n",
    "        try:\n",
    "            p = plot_box(df_[nn], df_[cn], f\"{nn} por {cn}\")\n",
    "            example_plots_bi.append(p)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "# Chi-cuadrado: cat vs cat\n",
    "chi_findings = []\n",
    "for i, c1 in enumerate(cat_cols[:5]):\n",
    "    for c2 in cat_cols[i+1: i+6]:\n",
    "        tab = pd.crosstab(df_[c1].astype(str), df_[c2].astype(str))\n",
    "        if tab.shape[0] > 1 and tab.shape[1] > 1:\n",
    "            chi2, p, dof, exp = chi2_contingency(tab)\n",
    "            chi_findings.append(f\"{c1} ~ {c2}: chi2={chi2:.1f}, p={p:.3g}\")\n",
    "\n",
    "bi_findings = []\n",
    "if len(top_corr)>0:\n",
    "    for (a,b), v in top_corr.items():\n",
    "        bi_findings.append(f\"Fuerte relación {a}~{b} (|r|={v:.2f})\")\n",
    "bi_findings += chi_findings[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdedc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Análisis multivariado ============\n",
    "example_plots_multi = []\n",
    "multi_findings = []\n",
    "\n",
    "# Preparar datos numéricos escalados para PCA\n",
    "if len(num_cols) >= 2:\n",
    "    X_num = df_[num_cols].copy()\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = scaler.fit_transform(imputer.fit_transform(X_num))\n",
    "    p_path, varexp = pca_plot(X_num_scaled, \"PCA sobre variables numéricas\")\n",
    "    example_plots_multi.append(p_path)\n",
    "    multi_findings.append(f\"PCA: Varianza explicada por 2 componentes = {varexp.sum():.2f}\")\n",
    "else:\n",
    "    varexp = np.array([])\n",
    "\n",
    "# Importancias (si hay target reconocible)\n",
    "target_col = auto_target(df_)\n",
    "if target_col is not None and target_col in df_.columns:\n",
    "    y = df_[target_col]\n",
    "    X = df_.drop(columns=[target_col])\n",
    "    num_cols2, cat_cols2 = detect_types(X)\n",
    "    # Pipeline simple de imputación/one-hot (solo para importancias rápidas)\n",
    "    X_num = X[num_cols2]\n",
    "    X_cat = X[cat_cols2].astype(\"category\")\n",
    "    X_cat = pd.get_dummies(X_cat, dummy_na=True, drop_first=False)\n",
    "    X_all = pd.concat([X_num, X_cat], axis=1)\n",
    "    X_all = X_all.fillna(X_all.median(numeric_only=True))\n",
    "\n",
    "    # Elegir tarea\n",
    "    if is_classification(y):\n",
    "        model = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    else:\n",
    "        model = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y if is_classification(y) else None)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if is_classification(y):\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)[:,1]\n",
    "            perf = roc_auc_score(y_test, y_proba)\n",
    "            multi_findings.append(f\"Modelo bosque aleatorio (baseline) AUC≈{perf:.3f}\")\n",
    "        except:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            multi_findings.append(f\"Modelo bosque aleatorio (baseline) ACC≈{acc:.3f}\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X_all.columns).sort_values(ascending=False).head(10)\n",
    "    else:\n",
    "        perf = r2_score(y_test, y_pred)\n",
    "        multi_findings.append(f\"Modelo bosque aleatorio (baseline) R2≈{perf:.3f}\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X_all.columns).sort_values(ascending=False).head(10)\n",
    "\n",
    "    plt.figure()\n",
    "    importances.iloc[::-1].plot(kind=\"barh\")\n",
    "    plt.title(\"Top 10 importancias de características (baseline)\")\n",
    "    imp_path = savefig(\"feature_importances\")\n",
    "    example_plots_multi.append(imp_path)\n",
    "else:\n",
    "    importances = pd.Series(dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307281c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============ Construcción de reporte (Word) ============\n",
    "context = {\n",
    "    \"author\": \"JLBM\",\n",
    "    \"date\": \"17/09/2025\",\n",
    "    \"n_rows\": int(df_.shape[0]),\n",
    "    \"n_cols\": int(df_.shape[1]),\n",
    "    \"target\": target_col if 'target_col' in globals() else None,\n",
    "    \"missing_top\": [(k, float(v)) for k,v in summarize_missing(df_).head(5).items()],\n",
    "    \"univariate_findings\": uni_findings[:10] if 'uni_findings' in globals() else [],\n",
    "    \"bivariate_findings\": bi_findings[:10] if 'bi_findings' in globals() else [],\n",
    "    \"multivariate_findings\": multi_findings[:10] if 'multi_findings' in globals() else [],\n",
    "    \"conclusions\": [],\n",
    "    \"example_plots\": {\n",
    "        \"univariate\": example_plots_uni if 'example_plots_uni' in globals() else [],\n",
    "        \"bivariate\": example_plots_bi if 'example_plots_bi' in globals() else [],\n",
    "        \"multivariate\": example_plots_multi if 'example_plots_multi' in globals() else [],\n",
    "    }\n",
    "}\n",
    "# Reglas de conclusiones automáticas (breves)\n",
    "if context['missing_top']:\n",
    "    context['conclusions'].append(\"Existen variables con valores faltantes que requerirán imputación.\")\n",
    "if len(context['bivariate_findings'])>0:\n",
    "    context['conclusions'].append(\"Se identificaron relaciones entre variables que orientan la selección de características.\")\n",
    "if len(context['multivariate_findings'])>0:\n",
    "    context['conclusions'].append(\"Un modelo baseline ofrece una referencia inicial de desempeño.\")\n",
    "if len(context['conclusions'])==0:\n",
    "    context['conclusions'].append(\"No se detectaron hallazgos críticos en la exploración inicial.\")\n",
    "\n",
    "report_path = build_report(context)\n",
    "print(\"✅ Reporte generado:\", report_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76c094",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Notas\n",
    "- Las figuras se guardan en la carpeta `outputs/`.\n",
    "- El reporte Word se guarda en la raíz del proyecto como **report_eda_heart_disease v1.docx** (máximo ~7 páginas, con resúmenes e ilustraciones).\n",
    "- Este EDA es reproducible y sirve como base para la siguiente fase de modelado (selección de variables y validación).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
